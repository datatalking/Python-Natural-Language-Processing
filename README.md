[![Python Support](https://img.shields.io/pypi/pyversions/cfg_load.svg)](https://pypi.org/project/cfg_load/)
[![Documentation Status](https://readthedocs.org/projects/cfg_load/badge/?version=latest)](http://cfg-load.readthedocs.io/en/latest/)
[![Build Status](https://travis-ci.org/MartinThoma/cfg_load.svg?branch=master)](https://travis-ci.org/MartinThoma/cfg_load)
[![Coverage Status](https://coveralls.io/repos/github/MartinThoma/cfg_load/badge.svg?branch=master)](https://coveralls.io/github/MartinThoma/cfg_load?branch=master)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

##### Thanks to https://github.com/MartinThoma/cfg_load best practices

# Python Natural Language Processing
This is the code repository for [Python Natural Language Processing](https://www.packtpub.com/big-data-and-business-intelligence/python-natural-language-processing?utm_source=github&utm_medium=repository&utm_campaign=9781787121423),
published by [Packt](https://www.packtpub.com/?utm_source=github). It contains all the supporting project files necessary
to work through the book from start to finish.
## About the Book
This book starts off by laying the foundation for Natural Language Processing and gives you a better understanding of
available free forms of corpus and different types of dataset. After this, you will know how to choose a dataset for
natural language processing applications and find the right NLP techniques to process sentences in datasets and
understand their structure. You will also learn how to tokenize different parts of sentences and ways to analyze them.



## Usage* This is for my personal use and documentation for brushing up on NLP.

* TODO - In process - Updated script for jupyternotebook, python3 and colab imports due to deprications since 2017 when first written
* needed to upload the csv manually as google colab is not very efficent


## In Development

* Add coverage tests
  Check tests with `tox`.


## Instructions and Navigation
All of the code is organized into folders. Each folder starts with a number followed by the application name. For example, Chapter02.



The code will look like the following:
```
import nltk
from nltk.corpus import brown as cb
from nltk.corpus import gutenberg as cg
```

Let's discuss some prerequisites for this book. Don't worry, it's not math or statistics, just
basic Python coding syntax is all you need to know. Apart from that, you need Python 2.7.X
or Python 3.5.X installed on your computer; I recommend using any Linux operating
system as well.
The list of Python dependencies can be found at GitHub repository at https://github.com/jalajthanaki/NLPython/blob/master/pip-requirements.txt.
Now let's look at the hardware required for this book. A computer with 4 GB RAM and at
least a two-core CPU is good enough to execute the code, but for machine learning and
deep learning examples, you may have more RAM, perhaps 8 GB or 16 GB, and
computational power that uses GPU(s).

## Related Products
* [Natural Language Processing: Python and NLTK](https://www.packtpub.com/big-data-and-business-intelligence/natural-language-processing-python-and-nltk?utm_source=github&utm_medium=repository&utm_campaign=9781787285101)

* [Mastering Natural Language Processing with Python](https://www.packtpub.com/big-data-and-business-intelligence/mastering-natural-language-processing-python?utm_source=github&utm_medium=repository&utm_campaign=9781783989041)

* [Natural Language Processing with Java - Second Edition](https://www.packtpub.com/big-data-and-business-intelligence/natural-language-processing-java-second-edition?utm_source=github&utm_medium=repository&utm_campaign=9781787288072)

